{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7a846f-33bf-47ba-a5d3-617d33a0cc23",
   "metadata": {},
   "source": [
    "Example of the process of doing DEMs for all orbits for a given observation of an AR â€“ where we don't window out any intervals because of shifts, etc. Instead, we will save energy-specific information about the percent of NuSTAR emission in the chosen region as a function of time, for later inspection. This will help identify cases where pointing shifts might cause unphysical distortion to the DEM inputs. \n",
    "\n",
    "Note: auto-download of an AIA file (for use in the initial co-alignmnet) will break while the JSOC is still down. We will add a thing where you can point to an existing AIA file instead.\n",
    "\n",
    "Overview:\n",
    "\n",
    "- Define orbits\n",
    "- Run time interval selection\n",
    "- Examine resulting intervals\n",
    "- Manually establish a co-alignment shift between NuSTAR and AIA\n",
    "- Automatically find co-alignment shifts + make regions for all other time intervals (note: this relies on the assumption that the COM is a good representation of the location of the brightest source, i.e. that the NuSTAR data is primarially one blob).\n",
    "- Save AIA region files for NCCS input\n",
    "- NOT IN THIS NOTEBOOK: YOU THEN TAKE THOSE AND MAKE AIA INPUTS ON THE NCCS\n",
    "- Conduct AIA/NuSTAR DEMs as a function of time, given all the above\n",
    "- Plot results.\n",
    "- Print some stats about \"left out\" times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb34388-bbab-4eba-bb6d-4acab7759d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# from astropy.io import fits\n",
    "# from astropy import units as u\n",
    "# import importlib\n",
    "# import pathlib\n",
    "\n",
    "#Path to top-level do-dem directory - edit for your system.\n",
    "path_to_dodem = '/Users/jmdunca2/do-dem/'\n",
    "from sys import path as sys_path\n",
    "sys_path.append(path_to_dodem+'/dodem/')\n",
    "\n",
    "import nustar_dem_prep as nu\n",
    "# import initial_analysis as ia\n",
    "# import orbit_auto as oa\n",
    "import time_interval_selection as tis\n",
    "import nustar_utilities as nuutil\n",
    "# import gauss2D as g2d\n",
    "import all_nu_analysis as ana\n",
    "import visualize_dem_results as viz\n",
    "import images_and_coalignment as iac\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pathlib\n",
    "import importlib\n",
    "import numpy as np\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91255572-65ec-4bd0-9a8c-4b3fa8ce9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dem_scripts(keys, runname='', where='./scripts/',\n",
    "                    high_temp_analysis=False):\n",
    "\n",
    "    if high_temp_analysis:\n",
    "        templatefile = where+'/dems_hitemp_key.py'\n",
    "    else:\n",
    "        templatefile = where+'/dems_key.py'\n",
    "    \n",
    "    pystrings = []\n",
    "    for key in keys:\n",
    "        pyfile = where+'dems_'+key+'.py'\n",
    "        pystring = 'python '+pyfile+' > '+' '+where+'dems_out_'+key+'.txt &'\n",
    "        #print(pystring)\n",
    "        pystrings.append(pystring)\n",
    "        \n",
    "        with open(templatefile, 'r') as f:\n",
    "            lines = f.read()\n",
    "            llist = lines.split('\\n')\n",
    "            #print(productslist)\n",
    "            llist[9] = 'key = \"'+key+'\"'\n",
    "            #print(llist)\n",
    "            newlist = '\\n'.join(llist)\n",
    "        \n",
    "            with open(pyfile, 'w') as file_out:\n",
    "                file_out.seek(0)\n",
    "                file_out.write(newlist)\n",
    "                file_out.truncate()\n",
    "\n",
    "\n",
    "    with open(where+'run_dems.sh', 'r') as f:\n",
    "        lines = f.read()\n",
    "        llist = lines.split('\\n')\n",
    "        llist.extend(['','',])\n",
    "        llist.extend(pystrings)\n",
    "        llist.extend(['wait', '', 'echo \"all orbit scripts finished\"'])\n",
    "        pylist = '\\n'.join(llist)\n",
    "\n",
    "        with open(where+runname+'_run_dems.sh', 'w') as file_out:\n",
    "            file_out.seek(0)\n",
    "            file_out.write(pylist)\n",
    "            file_out.truncate()\n",
    "\n",
    "\n",
    "\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "keys = data.keys()\n",
    "print(keys)\n",
    "\n",
    "xrt_rerun_keys = ['19-feb-16', '22-apr-16_2',\n",
    "                  '11-sep-17', '12-sep-17', '13-sep-17',\n",
    "                  '29-may-18_1',\n",
    "                  '12-apr-19', '13-apr-19',\n",
    "                  '29-jan-20', \n",
    "                  '29-apr-21',  '03-may-21_1', '03-may-21_2', \n",
    "                  '30-jul-21_1', '30-jul-21_2']\n",
    "\n",
    "keys = xrt_rerun_keys\n",
    "\n",
    "\n",
    "nan_rerun_keys = ['01-sep-15',\n",
    "                  '11-sep-17', '13-sep-17',\n",
    "                  '29-may-18_1',\n",
    "                 '29-apr-21', '30-jul-21_1']\n",
    "\n",
    "#keys = ['08-jun-20', '08-jan-21', '26-jul-16_2']\n",
    "\n",
    "#reruns = ['26-jul-16_1', '19-feb-16', '02-sep-15']\n",
    "\n",
    "make_dem_scripts(keys, runname='run_aiaxrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d12d2-2f7d-4419-abd0-a5f1918d2d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92360e5-7937-4b63-afec-fe53c0bf6202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rerun all, (hightemp analysis to do rescale)\n",
    "\n",
    "importlib.reload(ana)\n",
    "\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "keys = data.keys()\n",
    "\n",
    "thekey=['12-sep-17']\n",
    "the_need_images_keys=['19-feb-16', '29-jan-20'] #run whenever (split between this and xrt_debug nb)\n",
    "the_need_rerun_keys=['11-sep-17', '12-sep-17', '13-sep-17', '12-apr-19', '13-apr-19'] #run while on MSFC VPN - need IDL for responses\n",
    "\n",
    "#for key in list(keys)[8:]:\n",
    "for key in thekey:\n",
    "    print(key)\n",
    "    if key =='22-apr-16_1':\n",
    "        continue\n",
    "    ARDict = data[key]\n",
    "    id_dirs = ARDict['datapaths']\n",
    "    working_dir = ARDict['working_dir']\n",
    "    method = ARDict['method']\n",
    "\n",
    "    ARDict['prepped_aia'] = working_dir+'all_aia_dicts_'+key+'_post/'\n",
    "\n",
    "    data[key] = ARDict\n",
    "\n",
    "    with open('all_targets.pickle', 'wb') as f:\n",
    "             # Pickle the 'data' dictionary using the highest protocol available.\n",
    "             pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "    for id in id_dirs:\n",
    "        evt_data, hdr = nu.return_submap(datapath=id, fpm='A', return_evt_hdr=True)\n",
    "        time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "        timerange = [time0, time1]\n",
    "        print(timerange[0].strftime('%H-%M-%S'), timerange[1].strftime('%H-%M-%S'))\n",
    "    \n",
    "    ana.do_key_dem(key, plot_xrt=True, method=method, high_temp_analysis=False, rscl=True) #missing_last=True, missing_orbit=1, plot_xrt=False)\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93136ed1-52a8-4953-ad8c-1e855ca1f2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b88245-59ce-4533-885d-8d3d648d96e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '/Users/jmdunca2/do-dem/initial_dem_7may21/all_aia_dicts_07-may-21_post/orbit_20617005001/20-59-50_22-00-03_aia_prep.pickle'\n",
    "file = '/Users/jmdunca2/do-dem/initial_dem_26jul16_1/all_aia_dicts_26-jul-16_1_post/orbit_20201001001/19-22-55_20-23-20_aia_prep.pickle'\n",
    "\n",
    "\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.keys()\n",
    "print(data['region1']['aia_dn_s_px'][-3:], data['region1']['newerr'][-3:])\n",
    "print(data['region0']['aia_dn_s_px'][-3:], data['region0']['newerr'][-3:])\n",
    "\n",
    "\n",
    "#file = '/Users/jmdunca2/do-dem/initial_dem_7may21/all_aia_dicts_07-may-21_post/orbit_20617005001/20-59-50_22-00-03_aia_prep.pickle'\n",
    "file = '/Users/jmdunca2/do-dem/initial_dem_26jul16_1/all_aia_dicts_26-jul-16_1_post/orbit_20201001001/19-22-55_19-23-25_aia_prep.pickle'\n",
    "\n",
    "\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "\n",
    "data2.keys()\n",
    "print(data2['region1']['aia_dn_s_px'][-3:], data2['region1']['newerr'][-3:])\n",
    "print(data2['region0']['aia_dn_s_px'][-3:], data2['region0']['newerr'][-3:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09af7cc-eebc-426c-93f8-3db4bc18c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "colors = ['red','orange','springgreen', 'green', 'dodgerblue', 'purple']\n",
    "\n",
    "chanax = data['region1']['chans']\n",
    "dn_in = data['region1']['aia_dn_s_px']\n",
    "trmatrix = data['region1']['aia_tr']\n",
    "temps = data['region1']['tresp_logt']\n",
    "\n",
    "for i in np.arange(len(chanax)):\n",
    "    plt.semilogy(temps, dn_in[i]/trmatrix[i,:],label=chanax[i],color=colors[i]) #,lw=4)\n",
    "\n",
    "chanax = data2['region1']['chans']\n",
    "dn_in = data2['region1']['aia_dn_s_px']\n",
    "trmatrix = data2['region1']['aia_tr']\n",
    "temps = data2['region1']['tresp_logt']\n",
    "\n",
    "for i in np.arange(len(chanax)):\n",
    "    plt.semilogy(temps, dn_in[i]/trmatrix[i,:],label=chanax[i], linestyle=':',color=colors[i])#,color=clrs[i],lw=4)\n",
    "\n",
    "plt.xlim(5.7,7.2)\n",
    "plt.ylim(1e26,1e33)\n",
    "\n",
    "\n",
    "all_loci = np.zeros((len(chanax), len(temps)))\n",
    "for i in np.arange(len(chanax)):\n",
    "    all_loci[i,:] =  dn_in[i]/trmatrix[i,:]\n",
    "\n",
    "\n",
    "min_loci = np.min(all_loci, axis=0)\n",
    "\n",
    "\n",
    "plt.semilogy(temps, min_loci, label='minima', color='black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475db12a-0d36-4d23-a510-10ae1d956231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get minimum loci value as a function of temperature\n",
    "\n",
    "all_loci = np.zeros((len(chanax), len(temps)))\n",
    "for i in np.arange(len(chanax)):\n",
    "    all_loci[i,:] =  dn_in[i]/trmatrix[i,:]\n",
    "\n",
    "\n",
    "print(all_loci)\n",
    "\n",
    "min_loci = np.min(all_loci, axis=0)\n",
    "min_loci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b13ce-6469-4912-b6fe-65305b4512ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/jmdunca2/do-dem/initial_dem_29apr21/14-53-45_14-59-45/14-53-45_14-59-45_5.6_7.2_29-apr-21_MC_DEM_result.pickle'\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23533a38-456b-45b4-8f3d-03f7efa6653d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34245480-dbc3-4426-8fb5-d7a6ca146931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importlib.reload(ana)\n",
    "# key = '26-jul-16_2'\n",
    "\n",
    "# #===============================================================\n",
    "# #Update dictionary to have correct aia path for NCCS-prepped data.\n",
    "# #===============================================================\n",
    "# with open('all_targets.pickle', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# ARDict = data[key]\n",
    "\n",
    "# id_dirs = ARDict['datapaths']\n",
    "# obsids = ARDict['obsids']\n",
    "# working_dir = ARDict['working_dir']\n",
    "# method = ARDict['method']\n",
    "\n",
    "# ARDict['prepped_aia'] = working_dir+'all_aia_dicts_'+key+'_post/'\n",
    "\n",
    "# data[key] = ARDict\n",
    "\n",
    "# with open('all_targets.pickle', 'wb') as f:\n",
    "#          # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#          pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "# #===============================================================\n",
    "# #DO DEMS\n",
    "\n",
    "\n",
    "# for id in id_dirs:\n",
    "#     evt_data, hdr = nu.return_submap(datapath=id, fpm='A', return_evt_hdr=True)\n",
    "#     time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "#     timerange = [time0, time1]\n",
    "#     print(timerange[0].strftime('%H-%M-%S'), timerange[1].strftime('%H-%M-%S'))\n",
    "\n",
    "# ana.do_key_dem(key, plot_xrt=False, method=method, high_temp_analysis=True, rscl=True) #missing_last=True, missing_orbit=1, plot_xrt=False)\n",
    "\n",
    "# #===============================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59de096-f467-4947-860e-fa49e850c14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd07fbb-186e-407c-a002-d23df0be2fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "o=2\n",
    "prepped_aia_dir=ARDict['prepped_aia']\n",
    "print(prepped_aia_dir)\n",
    "orbit_aia_dir = prepped_aia_dir+'/orbit_'+obsids[o]+'/'\n",
    "print(orbit_aia_dir)\n",
    "files = glob.glob(orbit_aia_dir+'/*')\n",
    "\n",
    "for filename in files: \n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    #print(data)\n",
    "    newdata = data['region0']\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(newdata, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99cf5f-f0e8-449a-ae17-1aae8257bb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_dems(key, method):\n",
    "\n",
    "\n",
    "    with open('all_targets.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    ARDict = data[key]\n",
    "    \n",
    "    id_dirs = ARDict['datapaths']\n",
    "    obsids = ARDict['obsids']\n",
    "    working_dir = ARDict['working_dir']\n",
    "    print(working_dir)\n",
    "\n",
    "    minT=5.6\n",
    "    maxT=7.2\n",
    "    \n",
    "    if method == 'fit':\n",
    "        all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True, \n",
    "                                                                    missing_last=False)\n",
    "    \n",
    "        for time in all_time_intervals_list:\n",
    "            timestring = time[0].strftime('%H-%M-%S')\n",
    "            stopstring = time[1].strftime('%H-%M-%S')\n",
    "            timestring=timestring+'_'+stopstring\n",
    "        \n",
    "            demfile = working_dir+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "            print(demfile)\n",
    "    \n",
    "            status = subprocess.call('cp '+demfile+' ./compact_results/', shell=True) \n",
    "    \n",
    "    \n",
    "    if method in ['input', 'double']:\n",
    "        if method=='input':\n",
    "            region_dirs = iac.find_region_dirs(working_dir)\n",
    "        if method=='double':\n",
    "            gauss_stats = ARDict['gauss_stats']\n",
    "            sep_axis = gauss_stats[0][0]\n",
    "            region_dirs = iac.find_direction_dirs(working_dir, sep_axis)\n",
    "            #print(region_dirs)\n",
    "    \n",
    "        all_all_time_intervals, fixit, all_all_time_intervals_list = tis.region_time_intervals(region_dirs, id_dirs, shush=True, list_=True) \n",
    "    \n",
    "        for i in range(0, len(region_dirs)):\n",
    "            atl = all_all_time_intervals_list[i]\n",
    "            r = region_dirs[i]\n",
    "    \n",
    "            for time in atl:\n",
    "                timestring = time[0].strftime('%H-%M-%S')\n",
    "                stopstring = time[1].strftime('%H-%M-%S')\n",
    "                timestring=timestring+'_'+stopstring\n",
    "            \n",
    "                demfile = r+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "                demfile_ = demfile.split('/')[-1][0:-7]+'_region_'+str(i)+'.pickle'\n",
    "                print(demfile_)\n",
    "        \n",
    "                status = subprocess.call('cp '+demfile+' ./compact_results/'+demfile_, shell=True) \n",
    "        \n",
    " \n",
    "\n",
    "keys = ['01-sep-15', '02-sep-15',\n",
    "        '19-feb-16', '22-apr-16_2', '26-jul-16_1', '27-jul-16_1', '26-jul-16_2',\n",
    "        '11-sep-17', '12-sep-17', '13-sep-17', '10-oct-17',\n",
    "        '29-may-18_1', '09-sep-18', '10-sep-18', \n",
    "        '12-apr-19', '13-apr-19', \n",
    "        '06-jun-20', '07-jun-20', \n",
    "        '08-jun-20', '09-jun-20',\n",
    "        '29-apr-21', '03-may-21_1', '03-may-21_2', '20-jul-21', \n",
    "        '30-jul-21_1', \n",
    "        '30-jul-21_2']\n",
    "\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    all_targets = pickle.load(f)\n",
    "\n",
    "for k in keys:\n",
    "    method = all_targets[k]['method']\n",
    "    move_dems(k, method)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf825430-dd64-4afa-b1d6-4f18c0c752a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "demfile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6814dad-1487-4b52-b6cd-07be6b443ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importlib.reload(ana)\n",
    "# key = '30-jul-21_1'\n",
    "# method='double'\n",
    "\n",
    "# #===============================================================\n",
    "# #Update dictionary to have correct aia path for NCCS-prepped data.\n",
    "# #===============================================================\n",
    "# with open('all_targets.pickle', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# ARDict = data[key]\n",
    "\n",
    "# id_dirs = ARDict['datapaths']\n",
    "# obsids = ARDict['obsids']\n",
    "# working_dir = ARDict['working_dir']\n",
    "\n",
    "# ARDict['prepped_aia'] = working_dir+'all_aia_dicts_'+key+'_post/'\n",
    "\n",
    "# data[key] = ARDict\n",
    "\n",
    "# with open('all_targets.pickle', 'wb') as f:\n",
    "#          # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#          pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "# #===============================================================\n",
    "# #DO DEMS\n",
    "\n",
    "# import initial_analysis as ia\n",
    "# import nustar_utilities as nuutil\n",
    "\n",
    "# for id in id_dirs:\n",
    "#     evt_data, hdr = nu.return_submap(datapath=id, fpm='A', return_evt_hdr=True)\n",
    "#     time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "#     timerange = [time0, time1]\n",
    "#     print(timerange[0].strftime('%H-%M-%S'), timerange[1].strftime('%H-%M-%S'))\n",
    "\n",
    "# ana.do_key_dem(key, plot_xrt=False, method=method) #missing_last=True, missing_orbit=1, plot_xrt=False)\n",
    "\n",
    "# #===============================================================\n",
    "\n",
    "\n",
    "# #===============================================================\n",
    "# #Copy DEM result files to common directory\n",
    "\n",
    "\n",
    "# minT=5.6\n",
    "# maxT=7.2\n",
    "\n",
    "# if method == 'fit':\n",
    "#     all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True, \n",
    "#                                                                 missing_last=False)\n",
    "    \n",
    "#     for time in all_time_intervals_list:\n",
    "#         timestring = time[0].strftime('%H-%M-%S')\n",
    "#         stopstring = time[1].strftime('%H-%M-%S')\n",
    "#         timestring=timestring+'_'+stopstring\n",
    "        \n",
    "#         demfile = working_dir+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "#         print(demfile)\n",
    "    \n",
    "#         status = subprocess.call('cp '+demfile+' ./compact_results/', shell=True) \n",
    "\n",
    "\n",
    "# if method in ['input', 'double']:\n",
    "#     if method=='input':\n",
    "#         region_dirs = iac.find_region_dirs(working_dir)\n",
    "#     if method=='double':\n",
    "#         gauss_stats = ARDict['gauss_stats']\n",
    "#         sep_axis = gauss_stats[0][0]\n",
    "#         region_dirs = iac.find_direction_dirs(working_dir, sep_axis)\n",
    "#         #print(region_dirs)\n",
    "\n",
    "#     all_all_time_intervals, fixit, all_all_time_intervals_list = tis.region_time_intervals(region_dirs, id_dirs, shush=True, list_=True) \n",
    "\n",
    "#     for i in range(0, len(region_dirs)):\n",
    "#         atl = all_all_time_intervals_list[i]\n",
    "#         r = region_dirs[i]\n",
    "\n",
    "#         for time in atl:\n",
    "#             timestring = time[0].strftime('%H-%M-%S')\n",
    "#             stopstring = time[1].strftime('%H-%M-%S')\n",
    "#             timestring=timestring+'_'+stopstring\n",
    "            \n",
    "#             demfile = r+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "#             demfile_ = demfile[70:-7]+'_region_'+str(i)+'.pickle'\n",
    "#             print(demfile_)\n",
    "        \n",
    "#             status = subprocess.call('cp '+demfile+' ./compact_results/'+demfile_, shell=True) \n",
    "    \n",
    "# #===============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de2993-891a-4eb0-a633-6f0be0db1e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(ana)\n",
    "key = '12-sep-17'\n",
    "method='input'\n",
    "\n",
    "#===============================================================\n",
    "#Update dictionary to have correct aia path for NCCS-prepped data.\n",
    "#===============================================================\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "ARDict = data[key]\n",
    "\n",
    "id_dirs = ARDict['datapaths']\n",
    "obsids = ARDict['obsids']\n",
    "working_dir = ARDict['working_dir']\n",
    "\n",
    "ARDict['prepped_aia'] = working_dir+'all_aia_dicts_'+key+'_post/'\n",
    "\n",
    "data[key] = ARDict\n",
    "\n",
    "with open('all_targets.pickle', 'wb') as f:\n",
    "         # Pickle the 'data' dictionary using the highest protocol available.\n",
    "         pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "#===============================================================\n",
    "#DO DEMS\n",
    "\n",
    "import nustar_utilities as nuutil\n",
    "\n",
    "for id in id_dirs:\n",
    "    evt_data, hdr = nu.return_submap(datapath=id, fpm='A', return_evt_hdr=True)\n",
    "    time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "    timerange = [time0, time1]\n",
    "    print(timerange[0].strftime('%H-%M-%S'), timerange[1].strftime('%H-%M-%S'))\n",
    "\n",
    "ana.do_key_dem(key, plot_xrt=False, method=method) #missing_last=True, missing_orbit=1, plot_xrt=False)\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "\n",
    "#===============================================================\n",
    "#Copy DEM result files to common directory\n",
    "\n",
    "\n",
    "minT=5.6\n",
    "maxT=7.2\n",
    "\n",
    "if method == 'fit':\n",
    "    all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True, \n",
    "                                                                missing_last=False)\n",
    "    \n",
    "    for time in all_time_intervals_list:\n",
    "        timestring = time[0].strftime('%H-%M-%S')\n",
    "        stopstring = time[1].strftime('%H-%M-%S')\n",
    "        timestring=timestring+'_'+stopstring\n",
    "        \n",
    "        demfile = working_dir+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "        print(demfile)\n",
    "    \n",
    "        status = subprocess.call('cp '+demfile+' ./compact_results/', shell=True) \n",
    "\n",
    "\n",
    "if method == 'input':\n",
    "    region_dirs = iac.find_region_dirs(working_dir)\n",
    "    all_all_time_intervals, fixit, all_all_time_intervals_list = tis.region_time_intervals(region_dirs, id_dirs, shush=True, list_=True)\n",
    "\n",
    "    for i in range(0, len(region_dirs)):\n",
    "        atl = all_all_time_intervals_list[i]\n",
    "        r = region_dirs[i]\n",
    "\n",
    "        for time in atl:\n",
    "            timestring = time[0].strftime('%H-%M-%S')\n",
    "            stopstring = time[1].strftime('%H-%M-%S')\n",
    "            timestring=timestring+'_'+stopstring\n",
    "            \n",
    "            demfile = r+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "            demfile_ = demfile[70:-7]+'_region_'+str(i)+'.pickle'\n",
    "            print(demfile_)\n",
    "        \n",
    "            status = subprocess.call('cp '+demfile+' ./compact_results/'+demfile_, shell=True) \n",
    "    \n",
    "#===============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee655846-e6cf-4615-a5e1-20ad0f4ab6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa41bf-6ea8-4b14-8123-afbd0202dd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbf00c-ab4e-4952-a481-19aeff7d6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('/Users/jmdunca2/do-dem/initial_dem_12sep17/region_0/20-56-30_20-57-00/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119a47a-1d92-4cd8-b5bd-d5899005772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ana)\n",
    "key = '09-sep-18'\n",
    "\n",
    "#===============================================================\n",
    "#Update dictionary to have correct aia path for NCCS-prepped data.\n",
    "#===============================================================\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "ARDict = data[key]\n",
    "\n",
    "id_dirs = ARDict['datapaths']\n",
    "obsids = ARDict['obsids']\n",
    "working_dir = ARDict['working_dir']\n",
    "\n",
    "ARDict['prepped_aia'] = working_dir+'all_aia_dicts_'+key+'_post/'\n",
    "\n",
    "data[key] = ARDict\n",
    "\n",
    "with open('all_targets.pickle', 'wb') as f:\n",
    "         # Pickle the 'data' dictionary using the highest protocol available.\n",
    "         pickle.dump(data, f, pickle.HIGHEST_PROTOCOL) \n",
    "\n",
    "#===============================================================\n",
    "#DO DEMS\n",
    "\n",
    "import initial_analysis as ia\n",
    "import nustar_utilities as nuutil\n",
    "\n",
    "for id in id_dirs:\n",
    "    evt_data, hdr = nu.return_submap(datapath=id, fpm='A', return_evt_hdr=True)\n",
    "    time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "    timerange = [time0, time1]\n",
    "    print(timerange[0].strftime('%H-%M-%S'), timerange[1].strftime('%H-%M-%S'))\n",
    "\n",
    "ana.do_key_dem(key, missing_last=True, missing_orbit=1, plot_xrt=False)\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "\n",
    "#===============================================================\n",
    "#Copy DEM result files to common directory\n",
    "\n",
    "\n",
    "minT=5.6\n",
    "maxT=7.2\n",
    "\n",
    "all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True, \n",
    "                                                                missing_last=False)\n",
    "\n",
    "for time in all_time_intervals_list:\n",
    "    timestring = time[0].strftime('%H-%M-%S')\n",
    "    stopstring = time[1].strftime('%H-%M-%S')\n",
    "    timestring=timestring+'_'+stopstring\n",
    "    \n",
    "    demfile = working_dir+timestring+'/'+timestring+'_'+str(minT)+'_'+str(maxT)+'_'+key+'_MC_DEM_result.pickle'\n",
    "    print(demfile)\n",
    "\n",
    "    status = subprocess.call('cp '+demfile+' ./compact_results/', shell=True) \n",
    "\n",
    "#===============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782efc0c-06dc-44d1-83ff-71c3bed3d246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = ['01-sep-15', '02-sep-15',\n",
    "        '26-jul-16_1', '27-jul-16_1',\n",
    "        '11-sep-17', '12-sep-17', '13-sep-17',\n",
    "        '29-may-18_1', '09-sep-18', '10-sep-18', \n",
    "        '12-apr-19', '13-apr-19', \n",
    "        '06-jun-20', '07-jun-20', \n",
    "        '08-jun-20', '09-jun-20',\n",
    "        '29-apr-21', '03-may-21_1', '03-may-21_2', '20-jul-21', \n",
    "        '30-jul-21_1', \n",
    "        '30-jul-21_2']\n",
    "\n",
    "with open('all_targets.pickle', 'rb') as f:\n",
    "    all_targets = pickle.load(f)\n",
    "    \n",
    "done_sources = {k: all_targets[k] for k in keys}\n",
    "ana.get_exposures(done_sources, dogoes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ede30-7494-4dc3-84e0-1a1f4969bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "aia_file = '/Users/jmdunca2/do-dem/initial_dem_6jun20/all_aia_dicts_06-jun-20_post/orbit_20611003001/20-59-25_20-59-55_aia_prep.pickle'\n",
    "with open(aia_file, 'rb') as f:\n",
    "    aia_dat = pickle.load(f)\n",
    "\n",
    "np.isnan(aia_dat['aia_dn_s_px']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b2fff-c667-4417-9b8e-ccb5e8b1ae35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf9e12-b3c4-4d18-894b-8d7131a0c8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48edcd7-00cb-418f-ade2-3a81d0eb0dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484495d-1948-4f5a-8347-7e4b9ad7beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_sources = {k: all_targets[k] for k in keys}\n",
    "ana.get_exposures(done_sources, dogoes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43970b2a-2e03-4aba-81e6-6617976ef4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fpmA.csv')\n",
    "starts = df['flare_start'].values\n",
    "stops = df['flare_end'].values\n",
    "\n",
    "for i in range(0, len(starts)-1):\n",
    "    print(starts[i], stops[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdff0f-f903-47a9-a1a2-d8bb2b71d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in flaretimes:\n",
    "    print(f[0], f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad489fb-ef94-404f-856d-e6e10f5abedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91480d89-8fe3-4eb4-b477-6ed6c1e2769a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flaretimes=[]\n",
    "nonflaretimes=[]\n",
    "for time in all_time_intervals_list:\n",
    "    b4 = [s < time[0] for s in starts]\n",
    "    ea = [s > time[0] for s in stops]\n",
    "    es = np.where(np.logical_and(b4, ea))\n",
    "\n",
    "    if es[0].size > 0:\n",
    "        #print(starts[es], stops[es])\n",
    "        #print(time)\n",
    "        flaretimes.append(time)\n",
    "        continue\n",
    "\n",
    "    b4 = [s > time[0] for s in starts]\n",
    "    ea = [s < time[1] for s in starts]\n",
    "    es = np.where(np.logical_and(b4, ea))\n",
    "\n",
    "    if es[0].size > 0:\n",
    "        #print(starts[es], stops[es])\n",
    "        #print(time)\n",
    "        flaretimes.append(time)\n",
    "        continue\n",
    "\n",
    "    nonflaretimes.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20ed52-2829-4a5a-8f12-5dfb52269568",
   "metadata": {},
   "source": [
    "For the time interval to overlap with a flare, it could either ENVELOP a flare, start before (and end during) start during (and end during) and start + end within the flare. \n",
    "\n",
    "- fstart tstart tend fend - ENVELOP\n",
    "- fstart tstart fend tend - STOPSIDE\n",
    "  \n",
    "- tstart fstart tend fend - STARTSIDE\n",
    "- tstart fstart fend tend - DURING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1660d-d276-4543-93ba-35b868f355ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "logbins = np.geomspace(np.min(all_above10s), np.max(all_above10s), 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,4), tight_layout = {'pad': 1})\n",
    "\n",
    "ax.hist(all_above10s, bins=logbins, color='skyblue', edgecolor='black')\n",
    "ax.set_xscale('log')\n",
    "ax.axvline(1.8e22, color='Red')\n",
    "ax.axvline(1.5e23, color='Red')\n",
    "ax.axvspan(1.8e22, 1.5e23, alpha=0.3, color='Red', label='Ishikawa (2017) 95% Interval')\n",
    "ax.set_ylabel('Number of intervals')\n",
    "ax.set_xlabel('EM Integrated >10 MK')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477b6ba-1277-401f-8c5a-d94b644adcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# #Set path to obsid directory - initial pipeline should have been run already.\n",
    "# ind=0\n",
    "# datapath=id_dirs[ind]\n",
    "# obsid=obsids[ind]\n",
    "\n",
    "# evt_data, hdr = nu.return_submap(datapath=datapath, fpm='A', return_evt_hdr=True)\n",
    "# time0, time1 = [nuutil.convert_nustar_time(hdr['TSTART']), nuutil.convert_nustar_time(hdr['TSTOP'])]\n",
    "# timerange = [time0.tt.datetime, time1.tt.datetime]\n",
    "# from datetime import timezone\n",
    "# timerange = [t.replace(tzinfo=timezone.utc) for t in timerange]\n",
    "\n",
    "# #Comment second line if you're not using this same example nustar orbit\n",
    "# #Edit it to include only the desired time interval (default- all times in file) once you've run this once\n",
    "# #timerange=[]\n",
    "# #timerange=[datetime.datetime(2018, 5, 29, 22, 22), datetime.datetime(2018, 5, 29, 23, 20)]\n",
    "\n",
    "# evtA = glob.glob(datapath+'/event_cl/*A06_cl.evt')\n",
    "# evtB = glob.glob(datapath+'/event_cl/*B06_cl.evt')\n",
    "# hkA  = glob.glob(datapath+'/hk/*A_fpm.hk')\n",
    "# hkB  = glob.glob(datapath+'/hk/*B_fpm.hk')\n",
    "\n",
    "# import lightcurves as lc\n",
    "\n",
    "# importlib.reload(lc)\n",
    "# lc.prepare_nustar_lightcurves(evtA, evtB, hkA, hkB, timebin=15, erange=[2.,4.], \n",
    "#                               livetime_corr=False, save_dir=working_dir)\n",
    "# lc.prepare_nustar_lightcurves(evtA, evtB, hkA, hkB, timebin=15, erange=[4.,6.], \n",
    "#                               livetime_corr=False, save_dir=working_dir)\n",
    "# lc.prepare_nustar_lightcurves(evtA, evtB, hkA, hkB, timebin=15, erange=[6.,10.], \n",
    "#                               livetime_corr=False, save_dir=working_dir)\n",
    "\n",
    "# lc.plot_nustar_lightcurves(eranges = [[2.,4.],[4.,6.],[6.,10.]],\n",
    "#                            timerange=timerange, save_dir=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f4bfa-5443-4cd7-a331-66504e32c05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
