{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7a846f-33bf-47ba-a5d3-617d33a0cc23",
   "metadata": {},
   "source": [
    "Example of the process of doing DEMs for all orbits for a given observation of an AR – where we attempt to remove pointing shift/SAA/etc intervals using Reed Masek's correlator methods. \n",
    "\n",
    "Note: this will break while the JSOC is still down, because it requests an AIA file for use in the initial co-alignmnet :( \n",
    "\n",
    "Overview:\n",
    "\n",
    "- Define orbits\n",
    "- Run correlator and time interval selection\n",
    "- Examine resulting intervals\n",
    "- Manually establish a co-alignment shift between NuSTAR and AIA\n",
    "- Automatically find co-alignment shifts + make regions for all other time intervals (note: this relies on the assumption that the COM is a good representation of the location of the brightest source, i.e. that the NuSTAR data is primarially one blob).\n",
    "- Save AIA region files for NCCS input\n",
    "- NOT IN THIS NOTEBOOK: YOU THEN TAKE THOSE AND MAKE AIA INPUTS ON THE NCCS\n",
    "- Conduct AIA/NuSTAR DEMs as a function of time, given all the above\n",
    "- Plot results.\n",
    "- Print some stats about \"left out\" times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb34388-bbab-4eba-bb6d-4acab7759d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "import importlib\n",
    "import pathlib\n",
    "\n",
    "#Path to top-level do-dem directory - edit for your system.\n",
    "path_to_dodem = '/Users/jmdunca2/do-dem/'\n",
    "from sys import path as sys_path\n",
    "sys_path.append(path_to_dodem+'/dodem/')\n",
    "\n",
    "import nustar_dem_prep as nu\n",
    "import initial_analysis as ia\n",
    "import orbit_auto as oa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac019f2-b892-43b6-91fd-8e082e8ba7f9",
   "metadata": {},
   "source": [
    "Pick your obsid directories, and make some decisions about time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d983554-91eb-42f9-884d-1f0982413580",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dirs = ['/Users/jmdunca2/nustar/apr-2021/20615001001/',\n",
    "           '/Users/jmdunca2/nustar/apr-2021/20615002001/',\n",
    "           '/Users/jmdunca2/nustar/apr-2021/20615003001/',\n",
    "           '/Users/jmdunca2/nustar/apr-2021/20615004001/',\n",
    "           '/Users/jmdunca2/nustar/apr-2021/20615005001/']\n",
    "\n",
    "obsids=['20615001001','20615002001','20615003001','20615004001','20615005001']\n",
    "\n",
    "#Name your working directory\n",
    "working_dir='./initial_dem_apr21/'\n",
    "\n",
    "#Make a new working directory for prepped data/etc if it doesn't yet exist\n",
    "save_path = pathlib.Path(working_dir)\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir()\n",
    "\n",
    "#timestep for examining data (making correlator object)\n",
    "t_corr = 2\n",
    "\n",
    "#minimum length of suborbit\n",
    "min_t = 30\n",
    "\n",
    "#minimum number of steps needed in a sufficiently-sized suborbit, based on the above. \n",
    "min_step = int(np.ceil(min_t/t_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160eec4-1427-45a5-b9e6-06ca828468f7",
   "metadata": {},
   "source": [
    "We want to split the data time interval into \"suborbits\" that each contain no correlator-identified pointing shifts, or SAAs. \n",
    "\n",
    "There will be some minimum suborbit time for which we can make a useful DEM (i.e. sufficient NuSTAR statistics). This will depend on observation livetime, so we want to make sure it can be changed (via min_step keyword).\n",
    "\n",
    "To do this we will create correlator objects for FPMB,A. This also will make correlator overview plots (saved), and make a good interval comparison plot. This takes about 3m the first time, and ~7s once you have saved your centroid files for each fpm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832213ca-6d8b-467c-bab5-1eac01911c6c",
   "metadata": {},
   "source": [
    "Let's get sub-orbits! To combine FPMA, FPMB information, we select for only times where both FPM come out \"good\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0886b4-004d-4f37-b44c-f98dd6c7f5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(oa)\n",
    "\n",
    "all_bad_grouptimes=[]\n",
    "badgrouptimes=[]\n",
    "orbittimes = []\n",
    "badintervals=[]\n",
    "for id in id_dirs:\n",
    "    print(id)\n",
    "    both_groupinds, both_grouptimes, bad_groups, bad_grouptimes, bad_ids = oa.get_suborbits(id, t_corr, min_step, plot=True)\n",
    "    all_bad_grouptimes.extend(bad_grouptimes)\n",
    "    badgrouptimes.append(bad_grouptimes)\n",
    "    bad_suborbits, all_intervals = oa.get_suborbit_intervals(both_grouptimes, id, working_dir, erange=[6.,10], \n",
    "                                                             force_both_fpm_always=True, shush=True)  \n",
    "    if bad_suborbits:\n",
    "        badintervals.append(bad_suborbits)\n",
    "    if all_intervals:\n",
    "        orbittimes.append(all_intervals)\n",
    "    print('')\n",
    "\n",
    "data = {'bad_grouptimes': badgrouptimes,\n",
    "        'all_bad_grouptimes': all_bad_grouptimes,\n",
    "        'bad_intervals': badintervals,\n",
    "        'orbit_times': orbittimes}\n",
    "\n",
    "import pickle\n",
    "\n",
    "file=working_dir+'_interval_info.pickle'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d26d6-96cc-424c-85cf-661d3313b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Bad Intervals (pointing shifts, SAA, etc): ', len(all_bad_grouptimes))\n",
    "print('These are: ')\n",
    "for b in all_bad_grouptimes:\n",
    "    print(b[0].strftime('%H-%M-%S'), b[1].strftime('%H-%M-%S'))\n",
    "    \n",
    "print('')\n",
    "count=0\n",
    "for b in badintervals:\n",
    "    for int in b:\n",
    "        count+=1\n",
    "print('Number of Intervals that failed time interval selection: ', count)\n",
    "print('These are: ')\n",
    "for b in badintervals:\n",
    "    for int in b:\n",
    "        print(int[0].strftime('%H-%M-%S'), int[1].strftime('%H-%M-%S'))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16306e-3425-4846-800f-fb11898b2346",
   "metadata": {},
   "source": [
    "Now, we want to take these suborbits and run time interval selection within each!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54852a-97af-4ab0-baa3-6caabf5022e9",
   "metadata": {},
   "source": [
    "Options when finding intervals:\n",
    "\n",
    "- __erange__ : set to highest energy range you want to use as a DEM input (higher energies = worse statistics)\n",
    "- __countmin__: number of real counts you want in each DEM interval.\n",
    "- __minimum_seconds__: set to a minimum duration for the DEM time intervals (optional, omit to not set a minimum). Effective minimum if not set is 5s (time binning of lightcurves). You could change this too by editing the lightcurve code. \n",
    "- __lctype__ : what kind of counts are you going to include? Options:\n",
    "    \n",
    "            'grade0' – grade 0 (FPMA,B sum)\n",
    "            'grade04' - grade 0-4  (FPMA,B sum)\n",
    "            'corr14' - grade 0 - (1/4)*grades 21-24 (FPMA, B sum)\n",
    "            'corr54' - grade 0-4 - (5/4)*grades 21-24 (FPMA, B sum)\n",
    "            \n",
    "- __fast_min_factor__: factor multiplied by countmin when making an initial estimate of how long an interval is needed (fast method, without region selection). Accounts for the fact that some emission may fall outside the region. Adjust as needed; a larger factor will make this more time-efficient (less chance you'll make spectral data products for any too-small time intervals + have to repeat), but a smaller factor will get you closer to maximally-fine sampling in time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5f459-93c2-4de2-a3a5-fb729e2c6752",
   "metadata": {},
   "source": [
    "Note on finding intervals: this is *slow* – it takes between 40 minutes to 3 hours on my machine for a single ~1 hr orbit, due to the need to make NuSTAR spectral data products for each interval. The brighter the source, the finer the time sampling, the longer it takes. But the spectral data products need to be made anyway to do DEMs, so it isn't a total waste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dad04d-2ccb-4745-95c4-662c36faf263",
   "metadata": {},
   "source": [
    "Now that we've found time intervals for each sub-orbit, let's print them all to inspect, and also check what % of the total NuSTAR emission is in the region as a function of time. This is also a nice way to visualize the relative length of the different suborbits and time intervals within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf793f3b-8480-448b-9e04-24f3ce0546cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(oa)\n",
    "\n",
    "all_time_intervals, all_time_intervals_list = oa.find_all_intervals(working_dir)\n",
    "\n",
    "allpercentsA, allpercentsB = oa.check_region_emission(all_time_intervals, working_dir, grade='0_4', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ff0aa-2e8b-4678-b1c8-71558e4abd61",
   "metadata": {},
   "source": [
    "In order to do DEMs for each of these time intervals we will need to, for each suborbit, co-align NuSTAR and AIA to get an AIA region corresponding to the NuSTAR region. NOTE: currently, this ends up outputting the FPMB shifted region as the AIA region – worth thinking in the future about whether to do this separately for the FPM in some scenarios?\n",
    "\n",
    "We first manually establish a shift for the lead (first) time interval of the first sub-orbit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263873ef-d917-4beb-a3b0-f154f8219f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(oa)\n",
    "import pickle\n",
    "\n",
    "time_interval = all_time_intervals[0][0]\n",
    "nushift=[75, -50]\n",
    "\n",
    "#(first run)\n",
    "#dict = oa.nu_aia_coalign(time_interval, working_dir, nushift, save_dict=True)\n",
    "\n",
    "time=time_interval\n",
    "timestring = time[0].strftime('%H-%M-%S')\n",
    "stopstring = time[1].strftime('%H-%M-%S')\n",
    "timestring=timestring+'_'+stopstring\n",
    "file=working_dir+timestring+'/'+timestring+'_aia_region.pickle'\n",
    "try:\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    dict = oa.nu_aia_coalign(time_interval, working_dir, nushift, save_dict=True, input_aia = data['map'])\n",
    "except FileNotFoundError: \n",
    "    print('what')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d938e-e5ca-4186-b88f-cb2293945981",
   "metadata": {},
   "source": [
    "Next, we use that time interval as a reference interval, and we automatically find co-alignment shifts for every other sub-orbit. This is done by taking the difference between the reference interval COM and each new COM, and adujusting the co-alignment shift based on that difference. Also, an adjustment is made for solar rotation based on the time difference between the current and reference intervals.\n",
    "\n",
    "Note that the regions, aia maps, shifts, etc. are saved (pickled) in each time interval directory (*_aia_region.pickle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82197671-d1d0-4c41-9afc-1142d296d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(oa)\n",
    "lead_intervals=[]\n",
    "for at in all_time_intervals:\n",
    "    lead_intervals.append(at[0])\n",
    "\n",
    "reference_interval=time_interval\n",
    "\n",
    "oa.coalign_based_on_prior(lead_intervals, working_dir, reference_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e817d-1521-4737-abc4-b1e228bb4e6c",
   "metadata": {},
   "source": [
    "Now, we want to make AIA region reference files for EVERY TIME INTERVAL (not just the first in each sub-orbit). The AIA regions for each lead time interval are also used for subsequent intervals in that suborbit. The files are placed into directories based on what nustar orbit\n",
    "(OBSID-labled) they occur during – this is useful on the NCCS, due to the organization of the AIA data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89e41-18aa-4d0d-9899-dfa449aaa190",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(oa)\n",
    "suborbit_dirs = oa.make_all_aia_dicts(all_time_intervals, working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba508bfd-3a54-456b-9d1a-4becb27447fb",
   "metadata": {},
   "source": [
    "Copy each of the below directories onto the NCCS, and then run AIA data prep for each. When done, re-copy them back for use in DEMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a71bd-f081-4ff0-bebe-2d650848a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(suborbit_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff36a54-1408-4c02-9a89-ed66929e411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What instruments are you using?\n",
    "#---------------------------------\n",
    "aia=True\n",
    "#---------------------------------\n",
    "eis=False\n",
    "xrt=False\n",
    "#---------------------------------\n",
    "plot=False\n",
    "#---------------------------------\n",
    "nustar=True\n",
    "#If nustar is being used, here are the chosen energy ranges:\n",
    "nuenergies=[[2.5,3.5],[3.5,6.], [6.,10.]]\n",
    "#---------------------------------\n",
    "\n",
    "#---------------------------------\n",
    "#---------------------------------\n",
    "#What temperature range would you like to use? (units: log(T))\n",
    "minT=5.6\n",
    "maxT=7.2\n",
    "\n",
    "#Would you prefer to plot temperatures in MK, or the default (logT)\n",
    "plotMK=False\n",
    "#---------------------------------\n",
    "#---------------------------------\n",
    "\n",
    "name='initial_dem_apr21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f04f3-0e0d-408b-a426-98c034b5e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AIA Error table - set path to location in your system.\n",
    "#errortab='/Users/jmdunca2/ssw/sdo/aia/response/aia_V3_error_table.txt'\n",
    "\n",
    "#Sunpy data directory (or wherever else you store your downloaded AIA data)\n",
    "#sunpy_dir='/Users/jmdunca2/sunpy/data/'\n",
    "\n",
    "#Path to top-level do-dem directory - edit for your system.\n",
    "path_to_dodem = '/Users/jmdunca2/do-dem/'\n",
    "\n",
    "import dodem\n",
    "\n",
    "importlib.reload(oa)\n",
    "\n",
    "for o in range(0, len(obsids)):\n",
    "\n",
    "    datapath=id_dirs[o]\n",
    "    gtifile=datapath+'event_cl/nu'+obsids[o]+'A06_gti.fits'\n",
    "    regfile=path_to_dodem+'starter_region.reg'\n",
    "\n",
    "    suborbit_dir = working_dir+'/orbit_'+obsids[o]+'/'\n",
    "\n",
    "    time_intervals = orbittimes[o]\n",
    "\n",
    "    for time in time_intervals:\n",
    "        print(time)\n",
    "\n",
    "        data, bl, tr = oa.read_interval_dicts(time, where=suborbit_dir, bltr=True)\n",
    "    \n",
    "        dodem.dodem(time, bl, tr, xrt=xrt, aia=aia, nustar=nustar, name=name,\n",
    "                                    plotMK=plotMK, minT=minT, maxT=maxT,\n",
    "                                    plotresp=False, working_directory=working_dir,\n",
    "                                    default_err=0.2, path_to_dodem=path_to_dodem,\n",
    "            \n",
    "                                    #demreg related\n",
    "                                    rgt_fact=1.2, max_iter=30,\n",
    "                                    reg_tweak=1, gloci=1, mc_in=True, mc_rounds=100, \n",
    "                                    \n",
    "                                    #nustar related \n",
    "                                    combine_fpm=True, nuenergies=nuenergies, make_nustar=True, \n",
    "                                    datapath=datapath, gtifile=gtifile,\n",
    "                                    COM_nustar_region=True, nuclobber=False, edit_regfile=True,\n",
    "            \n",
    "                                    #aia related\n",
    "                                    load_prepped_aia=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d2679-a303-488b-9945-ac12e0f10aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize_dem_results as viz\n",
    "\n",
    "time_intervals = all_time_intervals_list\n",
    "\n",
    "importlib.reload(viz)\n",
    "vals = viz.get_DEM_timeseries(time_intervals, working_dir, minT, maxT, name)    \n",
    "\n",
    "\n",
    "peaks=vals['peaks']\n",
    "peaksmk = [10**m1/1e6 for m1 in peaks]    \n",
    "\n",
    "backcolors=['pink', 'lavenderblush']\n",
    "color='Red'\n",
    "    \n",
    "viz.pretty_orbit_timeseries(time_intervals, peaksmk, 'DEM Peak Temperature (MK)', 'DEM Peak Temperature',\n",
    "                        color, backcolors, working_dir=working_dir)\n",
    "\n",
    "\n",
    "backcolors=['powderblue', 'aliceblue']\n",
    "color='Blue'\n",
    "\n",
    "above10s=np.array(vals['above10s'])\n",
    "above10s_=above10s[:,0]\n",
    "\n",
    "viz.pretty_orbit_timeseries(time_intervals, above10s_, 'EM (cm^-5)', 'Total EM >10 MK',\n",
    "                        color, backcolors, error=True, quantity_low=above10s[:,1], quantity_high=above10s[:,2], \n",
    "                        ylog=True, comparisonbar=True, comp_band=[1.8e22, 1.5e23, 'Ishikawa (2017) 95%'],\n",
    "                            working_dir=working_dir)\n",
    "\n",
    "backcolors=['powderblue', 'aliceblue']\n",
    "color='Green'\n",
    "\n",
    "above7s=np.array(vals['above7s'])\n",
    "above7s_=above7s[:,0]\n",
    "\n",
    "viz.pretty_orbit_timeseries(time_intervals, above7s_, 'EM (cm^-5)', 'Total EM >7 MK',\n",
    "                        color, backcolors, error=True, quantity_low=above7s[:,1], quantity_high=above7s[:,2], \n",
    "                        ylog=True, working_dir=working_dir)\n",
    "\n",
    "backcolors=['powderblue', 'aliceblue']\n",
    "color='Purple'\n",
    "\n",
    "above5s=np.array(vals['above5s'])\n",
    "above5s_=above5s[:,0]\n",
    "\n",
    "viz.pretty_orbit_timeseries(time_intervals, above5s_, 'EM (cm^-5)', 'Total EM >5 MK',\n",
    "                        color, backcolors, error=True, quantity_low=above5s[:,1], quantity_high=above5s[:,2], \n",
    "                        ylog=True, working_dir=working_dir)\n",
    "\n",
    "\n",
    "backcolors=['khaki', 'lemonchiffon']\n",
    "color='Orange'\n",
    "\n",
    "val=np.array(vals['low_powers'])\n",
    "\n",
    "viz.pretty_orbit_timeseries(time_intervals, val, 'Index', 'Lower Power Law',\n",
    "                        color, backcolors, error=False, working_dir=working_dir)\n",
    "\n",
    "\n",
    "backcolors=['khaki', 'lemonchiffon']\n",
    "color='Red'\n",
    "\n",
    "val=np.array(vals['hi_powers'])*-1\n",
    "\n",
    "viz.pretty_orbit_timeseries(time_intervals, val, 'Index', 'Upper Power Law',\n",
    "                        color, backcolors, error=False, working_dir=working_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b384d1-ddba-43b4-9422-cea6b0cdc666",
   "metadata": {},
   "source": [
    "Investigating anomalous times (see: third interval in fourth orbit with very low low power law index), at least some are correlated with what appear to be pointing shifts not identified by the correlator method – they are visible in the correlator plots, but fall below the threshold. We should keep an eye on this moving forward (as we try out these methods with other observations) to see if there is a different optimal threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0359b4-15db-4534-b987-0a522816be29",
   "metadata": {},
   "source": [
    "Now, we want to examine some \"left-out times\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1da8fd-9c57-4efd-b2ca-a24342dcb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file=working_dir+'_interval_info.pickle'\n",
    "with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "orbit_times=data['orbit_times']\n",
    "bad_intervals=data['bad_intervals']\n",
    "bad_grouptimes=data['bad_grouptimes']\n",
    "\n",
    "print('Number of Bad Intervals (pointing shifts, SAA, etc): ', len(bad_grouptimes))\n",
    "print('Those of length greater than our minimum interval time are: ')\n",
    "for b in bad_grouptimes:\n",
    "    for gt in b:\n",
    "        dur=(gt[1]-gt[0])\n",
    "        #print(b[0].strftime('%H-%M-%S'), b[1].strftime('%H-%M-%S'), 'duration: ', dur)\n",
    "        if dur.total_seconds() > min_t:\n",
    "            print(gt[0].strftime('%H-%M-%S'), gt[1].strftime('%H-%M-%S'), 'duration: ', dur)\n",
    "    \n",
    "print('')\n",
    "count=0\n",
    "for b in bad_intervals:\n",
    "    for int in b:\n",
    "        count+=1\n",
    "print('Number of Intervals that failed time interval selection: ', count)\n",
    "print('These are: ')\n",
    "for b in bad_intervals:\n",
    "    for int in b:\n",
    "        print(int[0].strftime('%H-%M-%S'), int[1].strftime('%H-%M-%S'))\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417d86a-1611-4c56-b8ac-6649e0d8bb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's do time interval selection on the bad intervals and see what happens!\n",
    "#Caveat – we want to save the files somewhere so they won't be found by our standard oa.find_all_intervals.\n",
    "\n",
    "new_working_dir=working_dir+'/snowflakes/'\n",
    "#Make a new working directory for prepped data/etc if it doesn't yet exist\n",
    "save_path = pathlib.Path(new_working_dir)\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir()\n",
    "\n",
    "failed_intervals=[]\n",
    "sucesses=[]\n",
    "for b in range(0, len(bad_grouptimes)):\n",
    "    gts = bad_grouptimes[b]\n",
    "    long_enough=[]\n",
    "    for gt in gts:\n",
    "        dur=(gt[1]-gt[0])\n",
    "        #print(b[0].strftime('%H-%M-%S'), b[1].strftime('%H-%M-%S'), 'duration: ', dur)\n",
    "        if dur.total_seconds() > min_t:\n",
    "            print(dur)\n",
    "            long_enough.append(gt)\n",
    "            \n",
    "    id=id_dirs[b]\n",
    "    bad_suborbits, all_intervals = oa.get_suborbit_intervals(long_enough, id, new_working_dir, erange=[6.,10], \n",
    "                                                             force_both_fpm_always=True, shush=True) \n",
    "\n",
    "    if bad_suborbits:\n",
    "        failed_intervals.append(bad_suborbits)\n",
    "    if all_intervals:\n",
    "        sucesses.append(all_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f444bd-a96f-4149-b802-dc50103cfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ff in failed_intervals:\n",
    "    for f in ff:\n",
    "        print(type(f[0]))\n",
    "        print(f[0].strftime('%H-%M-%S'), f[1].strftime('%H-%M-%S'), 'duration: ', (f[1]-f[0]))\n",
    "\n",
    "print('')\n",
    "for ff in sucesses:\n",
    "    for f in ff:\n",
    "        print(type(f[0].datetime))\n",
    "        print(f[0].strftime('%H-%M-%S'), f[1].strftime('%H-%M-%S'), 'duration: ', (f[1].datetime-f[0].datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5c34d-6064-4a4c-9b2b-e7f70cc1b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d06c85-8e2f-4451-b88a-4ca8653aabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single DEM test\n",
    "\n",
    "\n",
    "# #AIA Error table - set path to location in your system.\n",
    "# errortab='/Users/jmdunca2/ssw/sdo/aia/response/aia_V3_error_table.txt'\n",
    "\n",
    "# #Sunpy data directory (or wherever else you store your downloaded AIA data)\n",
    "# sunpy_dir='/Users/jmdunca2/sunpy/data/'\n",
    "\n",
    "# #Path to top-level do-dem directory - edit for your system.\n",
    "# path_to_dodem = '/Users/jmdunca2/do-dem/'\n",
    "\n",
    "# import dodem\n",
    "\n",
    "# datapath=id_dir\n",
    "# gtifile=datapath+'event_cl/nu'+obsid+'A06_gti.fits'\n",
    "# regfile=path_to_dodem+'starter_region.reg'\n",
    "\n",
    "\n",
    "# ind=0\n",
    "# time = both_grouptimes[ind]\n",
    "# timestring = time[0].strftime('%H-%M-%S')\n",
    "# stopstring = time[1].strftime('%H-%M-%S')\n",
    "# timestring=timestring+'_'+stopstring\n",
    "# #suborbit directory\n",
    "# suborbit_dir=working_dir+'/suborbit_'+timestring\n",
    "\n",
    "# time_interval=time_intervals[0]\n",
    "# data, bl, tr = read_interval_dicts(time_interval, where=suborbit_dir, bltr=True)\n",
    "\n",
    "\n",
    "# importlib.reload(dodem)\n",
    "# #NuSTAR and AIA DEM\n",
    "# dodem.dodem(time_interval, bl, tr, xrt=xrt, aia=aia, nustar=nustar, name=name,\n",
    "#                                     plotMK=plotMK, minT=minT, maxT=maxT,\n",
    "#                                     plotresp=False, working_directory=working_dir,\n",
    "#                                     default_err=0.2, path_to_dodem=path_to_dodem,\n",
    "            \n",
    "#                                     #demreg related\n",
    "#                                     rgt_fact=1.2, max_iter=30,\n",
    "#                                     reg_tweak=1, gloci=1, mc_in=True, mc_rounds=100, \n",
    "                                    \n",
    "#                                     #nustar related \n",
    "#                                     combine_fpm=True, nuenergies=nuenergies, make_nustar=True, \n",
    "#                                     datapath=datapath, gtifile=gtifile,\n",
    "#                                     COM_nustar_region=True, nuclobber=False, edit_regfile=True,\n",
    "            \n",
    "#                                     #aia related\n",
    "#                                     load_prepped_aia=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5dce-3c89-4844-91e0-72ad2d396c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
