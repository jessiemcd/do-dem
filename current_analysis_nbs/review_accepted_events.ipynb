{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bf6c3-f4ce-4fd3-88b7-0cd61806a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dodem = '/Users/jmdunca2/do-dem/'\n",
    "from sys import path as sys_path\n",
    "sys_path.append(path_to_dodem+'/dodem/')\n",
    "\n",
    "import all_nu_analysis as ana\n",
    "import time_interval_selection as tis\n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy import units as u\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_good_stats(all_time_intervals, flarestarts, flarestops, check_acc=True):\n",
    "    \n",
    "    accthreshold=95\n",
    "    \n",
    "    all_good_times=[]\n",
    "    total_duration=0*u.s\n",
    "    orbit_durations=[]\n",
    "    for at in range(0, len(all_time_intervals)):\n",
    "        orbit_good_times=[]\n",
    "        orbit_duration=0*u.s\n",
    "        for tr in all_time_intervals[at]:\n",
    "            #print(tr)\n",
    "            if check_acc:\n",
    "                meanevsum, checkacc = ana.check_avg_rej(tr, id_dirs[at], threshold=accthreshold)\n",
    "                flare = ana.check_for_flare(tr, flarestarts, flarestops)\n",
    "                if checkacc and flare == False:\n",
    "                    print(tr[0].strftime('%Y-%m-%d %H:%M:%S'), tr[1].strftime('%H:%M:%S'))\n",
    "                    dur = (tr[1]-tr[0]).to(u.s)\n",
    "                    orbit_duration += dur\n",
    "                    print(orbit_duration)\n",
    "                    orbit_good_times.append(tr)\n",
    "            else:\n",
    "                flare = ana.check_for_flare(tr, flarestarts, flarestops)\n",
    "                if flare == False:\n",
    "                    print(tr[0].strftime('%Y-%m-%d %H:%M:%S'), tr[1].strftime('%H:%M:%S'))\n",
    "                    dur = (tr[1]-tr[0]).to(u.s)\n",
    "                    orbit_duration += dur\n",
    "                    print(orbit_duration)\n",
    "                    orbit_good_times.append(tr)\n",
    "                \n",
    "                \n",
    "        orbit_durations.append(orbit_duration)\n",
    "                \n",
    "        all_good_times.append(orbit_good_times)\n",
    "        total_duration+=orbit_duration\n",
    "\n",
    "    print('Total duration: ', total_duration.to(u.min))\n",
    "    for at in range(0, len(all_time_intervals)):\n",
    "        print('Orbit ', at, 'â€“ good intervals: ', len(all_good_times[at]), ' duration: ', orbit_durations[at].to(u.min))\n",
    "\n",
    "    return all_good_times\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b915ae-18a4-4f91-9622-5d1022430fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/jmdunca2/do-dem/reference_files/all_targets_postghost.pickle'\n",
    "missing_last=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcedb19-8329-46a0-a63f-688f69d18092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keys = ['24-feb-22', '25-feb-22', '27-feb-22', '03-jun-22', '06-sep-22']\n",
    "#keys = ['09-dec-22']#, \n",
    "#keys = ['10-dec-22']#, '18-mar-23_1','18-mar-23_2']\n",
    "keys = ['11-dec-22_2']#, \n",
    "keys = ['17-nov-21_1', '17-nov-21_2', '19-nov-21', '20-nov-21', '21-nov-21', '22-nov-21']\n",
    "keys = ['22-nov-21_1']\n",
    "keys = ['03-jun-22_2']\n",
    "keys = ['14-jan-21']\n",
    "#keys = [#'17-nov-21_1',\n",
    "       #'09-dec-22', #has good intervals if you allow times with >90% accepted instead of %95\n",
    "       #'10-dec-22', \n",
    "       # '06-sep-22'\n",
    "      #]\n",
    "\n",
    "keys = ['17-nov-21_1', #'03-jun-22_1', '06-sep-22','19-nov-21', '20-nov-21', \n",
    "        '22-nov-21_1', #'22-nov-21_2',\n",
    "          '03-jun-22_2', '09-dec-22']\n",
    "keys = ['09-dec-22']\n",
    "keys = ['29-jan-20']\n",
    "\n",
    "keys = ['19-nov-21']\n",
    "\n",
    "keys = ['29-may-18_2', '10-oct-17', '26-jul-16_1', '26-jul-16_2', '27-jul-16_1']\n",
    "keys = ['20-nov-21']\n",
    "\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "keys = list(data.keys())\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    ARDict = data[key]\n",
    "    \n",
    "    id_dirs = ARDict['datapaths']\n",
    "    #obsids = ARDict['obsids']\n",
    "    working_dir = ARDict['working_dir']\n",
    "    #prepped_aia_dir = ARDict['prepped_aia']\n",
    "    method=ARDict['method']\n",
    "    # if method=='double':\n",
    "    #     gauss_stats = ARDict['gauss_stats']\n",
    "    #     sep_axis = gauss_stats[0][0]\n",
    "    # else:\n",
    "    #     sep_axis = ''\n",
    "    \n",
    "    \n",
    "    if method in ['input', 'double']:\n",
    "        directories = ana.get_region_directories(key, targets_file=file)\n",
    "        all_all_time_intervals, fixit = tis.region_time_intervals(directories, id_dirs, shush=True)\n",
    "    \n",
    "    if method=='fit':\n",
    "        onegauss=True\n",
    "        regfile=path_to_dodem+'starter_region.reg'\n",
    "        all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True) \n",
    "\n",
    "\n",
    "    ana.make_summary_lcs(key, file, flarepath='./reference_files/',\n",
    "                     show=True, goes=True,\n",
    "                    accthreshold=95, pre_dem_nustar_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2aae8-7adf-4757-87f9-b3f51bdbbfc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = ['17-nov-21_1', '03-jun-22_1', '06-sep-22','19-nov-21', '20-nov-21', '22-nov-21_1', '22-nov-21_2',\n",
    "          '03-jun-22_2', '09-dec-22', '14-jan-21']\n",
    "keys = ['09-dec-22']\n",
    "\n",
    "keys = ['29-may-18_2', '10-oct-17', '26-jul-16_1', '26-jul-16_2', '27-jul-16_1', '20-nov-21']\n",
    "\n",
    "\n",
    "\n",
    "early_starts, late_stops = ana.get_saved_flares(flarepath='./reference_files/', add_stdv_flares=True, add_manual_flares=True)\n",
    "all_all_good_times = []\n",
    "for key in keys:\n",
    "    print('')\n",
    "    print('')\n",
    "    print(key)\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    ARDict = data[key]\n",
    "    \n",
    "    id_dirs = ARDict['datapaths']\n",
    "    #obsids = ARDict['obsids']\n",
    "    working_dir = ARDict['working_dir']\n",
    "    #prepped_aia_dir = ARDict['prepped_aia']\n",
    "    method=ARDict['method']\n",
    "    # if method=='double':\n",
    "    #     gauss_stats = ARDict['gauss_stats']\n",
    "    #     sep_axis = gauss_stats[0][0]\n",
    "    # else:\n",
    "    #     sep_axis = ''\n",
    "    \n",
    "    \n",
    "    if method in ['input', 'double']:\n",
    "        directories = ana.get_region_directories(key, targets_file=file)#, method=method)\n",
    "        print(directories)\n",
    "        all_all_time_intervals, fixit = tis.region_time_intervals(directories, id_dirs, shush=True)\n",
    "\n",
    "        count=0\n",
    "        for aat in all_all_time_intervals:\n",
    "            print('Region ', count)\n",
    "            all_good_times = get_good_stats(aat, early_starts, late_stops, check_acc=False)\n",
    "            count+=1\n",
    "            all_all_good_times.extend(all_good_times)\n",
    "\n",
    "    \n",
    "    \n",
    "    if method=='fit':\n",
    "        onegauss=True\n",
    "        regfile=path_to_dodem+'starter_region.reg'\n",
    "        all_time_intervals, all_time_intervals_list = tis.find_all_intervals(working_dir, shush=True) \n",
    "\n",
    "        all_good_times = get_good_stats(all_time_intervals, early_starts, late_stops, check_acc=False)\n",
    "\n",
    "        all_all_good_times.extend(all_good_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099248f4-b508-4bbe-b20d-3abcbdab1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'new_aia_times': all_all_good_times}\n",
    "\n",
    "with open('oldnew_aia_times.pickle', 'wb') as f:\n",
    "         # Pickle the 'data' dictionary using the highest protocol available.\n",
    "         pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0f3b6-916e-4934-967a-42c378f6e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_aia_times'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860e945-dbe4-40fb-a7b1-c429c0f0ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_aia_times'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d54d7a-18d0-4bbe-8932-00066063467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_aia_times'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa0d2c-034e-4eef-bbc8-dce4cd54114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(60+40+17+24+9+18+32+13+22+19)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6514b-ef12-4a90-a3b0-bdca9e47df37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Adding flares found for these observations using the standard-deviation-focused method to the list of all flares.\n",
    "# #keys = ['24-feb-22', '25-feb-22', '27-feb-22', '03-jun-22', '06-sep-22']\n",
    "\n",
    "# with open('/Users/jmdunca2/do-dem/reference_files/stdv_flares.pickle', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# for kk in keys:\n",
    "#     windows = ana.do_stdv_analysis(kk, file, show=True)\n",
    "#     data['stdv_flares'].extend(windows)\n",
    "\n",
    "\n",
    "\n",
    "# with open('/Users/jmdunca2/do-dem/reference_files/stdv_flares.pickle', 'wb') as f:\n",
    "#          # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#          pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778af5a-45e0-496d-9605-c2db8ada8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Specialized light curve for key that fails TIS.\n",
    "\n",
    "\n",
    "\n",
    "# import time_interval_selection as tis\n",
    "# import visualize_dem_results as viz\n",
    "# import gauss2D as g2d\n",
    "# import images_and_coalignment as iac\n",
    "# import nustar_dem_prep as nu\n",
    "# import lightcurves as lc\n",
    "# import glob\n",
    "\n",
    "# key='22-apr-16_1'\n",
    "\n",
    "# with open(file, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# ARDict = data[key]\n",
    "\n",
    "# id_dirs = ARDict['datapaths']\n",
    "# #obsids = ARDict['obsids']\n",
    "# working_dir = ARDict['working_dir']\n",
    "# #prepped_aia_dir = ARDict['prepped_aia']\n",
    "# method=ARDict['method']\n",
    "\n",
    "\n",
    "# nustar_acc_color='xkcd:apple'\n",
    "# nustar_cts_color=['xkcd:sky blue', 'xkcd:cerulean', 'xkcd:periwinkle', 'xkcd:cyan']\n",
    "\n",
    "# #NUSTAR - ALL-FOV, FINE TIME RESOLUTION ==========================================================================================\n",
    "\n",
    "# #tr=newtimerange\n",
    "\n",
    "\n",
    "# for datapath in id_dirs:\n",
    "\n",
    "#     fig, axes = plt.subplots(6, 1, figsize=(15, 15), sharex=True)\n",
    "#     plt.subplots_adjust(hspace=0)\n",
    "    \n",
    "#     evtA = glob.glob(datapath+'/event_cl/*A06_cl.evt')\n",
    "#     evtB = glob.glob(datapath+'/event_cl/*B06_cl.evt')\n",
    "#     hkA  = glob.glob(datapath+'/hk/*A_fpm.hk')\n",
    "#     hkB  = glob.glob(datapath+'/hk/*B_fpm.hk')\n",
    "    \n",
    "#     #Load in the evt file (has the list of photons)\n",
    "#     evtdataA, hdrA = lc.load_nufiles(evtA[0])\n",
    "#     # Load in the hk file (has the livetime info)\n",
    "#     lvdataA, lvhdrA = lc.load_nufiles(hkA[0])\n",
    "#     evtdataB, hdrB = lc.load_nufiles(evtB[0])\n",
    "#     lvdataB, lvhdrB = lc.load_nufiles(hkB[0])\n",
    "    \n",
    "    \n",
    "#     eranges=[[2.5,3.5],[3.5,6.], [6.,10.], [10.,15.]]\n",
    "#     labels = ['NuSTAR 2.5-3.5 keV', 'NuSTAR 3.5-6 keV', 'NuSTAR 6-10 keV', 'NuSTAR 10-15 keV']\n",
    "#     eind=0\n",
    "#     #     acc=0\n",
    "#     for erange in eranges:\n",
    "#         kevA = evtdataA['PI']*0.04+1.6\n",
    "#         erange_evtdataA = evtdataA[np.where(np.logical_and(kevA > erange[0],kevA < erange[1]))]\n",
    "#         kevB = evtdataB['PI']*0.04+1.6\n",
    "#         erange_evtdataB = evtdataB[np.where(np.logical_and(kevB > erange[0],kevB < erange[1]))]\n",
    "    \n",
    "    \n",
    "#         res = lc.get_a_nustar_lightcurve(erange_evtdataA, hdrA, lvdataA, lvhdrA, timebin=10, livetime_corr=True, event_stats=True)\n",
    "#         times_converted, countrateA, lvt, counts, acc_sample, rej_sample, all_sample = res\n",
    "      \n",
    "#         #keepinds = np.nonzero(np.logical_and(times_converted > tr[0], times_converted < tr[1]))\n",
    "#         #times_converted=times_converted[keepinds]\n",
    "#         #countrateA=countrate[keepinds]   \n",
    "    \n",
    "#         #acc_sample=acc_sample[keepinds]\n",
    "#         #rej_sample=rej_sample[keepinds]\n",
    "#         evsumA=acc_sample/(acc_sample+rej_sample)*100\n",
    "    \n",
    "            \n",
    "#         res = lc.get_a_nustar_lightcurve(erange_evtdataB, hdrB, lvdataB, lvhdrB, timebin=10, livetime_corr=True, event_stats=True)\n",
    "#         times_converted, countrateB, lvt, counts, acc_sample, rej_sample, all_sample = res\n",
    "    \n",
    "    \n",
    "#         #keepinds = np.nonzero(np.logical_and(times_converted > tr[0], times_converted < tr[1]))\n",
    "#         #times_converted=times_converted[keepinds]\n",
    "#         #countrateB=countrate[keepinds]\n",
    "    \n",
    "#         #acc_sample=acc_sample[keepinds]\n",
    "#         #rej_sample=rej_sample[keepinds]\n",
    "    \n",
    "#         evsumB=acc_sample/(acc_sample+rej_sample)*100\n",
    "    \n",
    "    \n",
    "#         #evsum = (np.array(evsumA)+np.array(evsumB))/2.\n",
    "#         evsum = (np.array(evsumA)+np.array(evsumB))/2.\n",
    "    \n",
    "        \n",
    "#         axes[3].plot(times_converted, evsum, label='Accepted Event %', color=nustar_acc_color)\n",
    "    \n",
    "#         totalrate = countrateA+countrateB\n",
    "#         totalrate_vals = totalrate[np.isfinite(totalrate)]\n",
    "#         maximum = np.nanmax(totalrate_vals) \n",
    "#         axes[2].plot(times_converted, totalrate/maximum, label=labels[eind], color=nustar_cts_color[eind]) \n",
    "    \n",
    "    \n",
    "#         eind+=1\n",
    "    \n",
    "# axes[2].set_ylim([0,1.01])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14b3d0-654c-4631-a834-0a11c548d7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
